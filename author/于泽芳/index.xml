<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>于泽芳 | 智能计算机体系结构实验室</title>
    <link>http://localhost:1313/author/%E4%BA%8E%E6%B3%BD%E8%8A%B3/</link>
      <atom:link href="http://localhost:1313/author/%E4%BA%8E%E6%B3%BD%E8%8A%B3/index.xml" rel="self" type="application/rss+xml" />
    <description>于泽芳</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh-Hans</language><copyright>© 2024 智能计算机体系结构实验室 · 上海交通大学</copyright><lastBuildDate>Thu, 05 Dec 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/author/%E4%BA%8E%E6%B3%BD%E8%8A%B3/avatar_hue888d6e5a219d7fc7c142f3ac7ab3e4f_315738_270x270_fill_q75_lanczos_center.jpg</url>
      <title>于泽芳</title>
      <link>http://localhost:1313/author/%E4%BA%8E%E6%B3%BD%E8%8A%B3/</link>
    </image>
    
    <item>
      <title>于泽芳</title>
      <link>http://localhost:1313/author/%E4%BA%8E%E6%B3%BD%E8%8A%B3/</link>
      <pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/author/%E4%BA%8E%E6%B3%BD%E8%8A%B3/</guid>
      <description>&lt;p&gt;Need to fill the bio&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GIST: Improving Parameter Efficient Fine Tuning via Knowledge Interaction</title>
      <link>http://localhost:1313/publication/ruan2024gist/</link>
      <pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/ruan2024gist/</guid>
      <description></description>
    </item>
    
    <item>
      <title>From Raw Video to Pedagogical Insights: A Unified Framework for Student Behavior Analysis</title>
      <link>http://localhost:1313/publication/yu2024raw/</link>
      <pubDate>Wed, 07 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/yu2024raw/</guid>
      <description></description>
    </item>
    
    <item>
      <title>LAMM: Label Alignment for Multi-Modal Prompt Learning</title>
      <link>http://localhost:1313/publication/gao2024lamm/</link>
      <pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/gao2024lamm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning to Floorplan like Human Experts via Reinforcement Learning</title>
      <link>http://localhost:1313/publication/yan2024date/</link>
      <pubDate>Thu, 15 Feb 2024 14:00:05 +0800</pubDate>
      <guid>http://localhost:1313/publication/yan2024date/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Deep multimodal representation learning for generalizable person re-identification</title>
      <link>http://localhost:1313/publication/xiang-2024-rethink/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/xiang-2024-rethink/</guid>
      <description></description>
    </item>
    
    <item>
      <title>AV-TAD: Audio-Visual Temporal Action Detection with Transformer</title>
      <link>http://localhost:1313/publication/li2023avtad/</link>
      <pubDate>Wed, 15 Feb 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/li2023avtad/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CC-PoseNet: Towards human pose estimation in crowded classrooms</title>
      <link>http://localhost:1313/publication/yu2023ccposenet/</link>
      <pubDate>Wed, 15 Feb 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/yu2023ccposenet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SynPose: A Large-scale and Densely Annotated Synthetic Dataset for Human Pose Estimation in Classroom</title>
      <link>http://localhost:1313/publication/yu2022synthetic/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/yu2022synthetic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>基于骨架的人类动作识别</title>
      <link>http://localhost:1313/project/skeleton/</link>
      <pubDate>Mon, 21 Jun 2021 10:00:00 +0800</pubDate>
      <guid>http://localhost:1313/project/skeleton/</guid>
      <description>&lt;h3 id=&#34;背景介绍&#34;&gt;背景介绍&lt;/h3&gt;
&lt;p&gt;近年来，基于骨架的动作识别由于其对动态环境和复杂背景的鲁棒性而备受关注，其主要任务为根据输入的一段骨架序列，输出当前对应的动作类别。主流方法通常将关节点数据构建为图（graph）结构，并将图卷积扩展为时空图卷积来提取运动信息。&lt;/p&gt;
&lt;h3 id=&#34;应用场景&#34;&gt;应用场景&lt;/h3&gt;
&lt;p&gt;基于骨架的动作识别可以服务于人机交互、机器人、VR游戏实时控制等领域。&lt;/p&gt;
&lt;h3 id=&#34;已有成果&#34;&gt;已有成果&lt;/h3&gt;
&lt;p&gt;构建动作识别数据集时往往需耗费大量的人力物力，缺乏多视角下的动作序列。为解决这一问题，我们基于GTA V游戏构建了大规模360度全视角的虚拟动作数据集GAR-60。


















&lt;figure id=&#34;figure-gar-60数据集部分样本&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./gar-60.png&#34; data-caption=&#34;GAR-60数据集部分样本&#34;&gt;


  &lt;img src=&#34;./gar-60.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    GAR-60数据集部分样本
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
