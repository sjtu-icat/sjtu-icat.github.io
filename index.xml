<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>智能计算机体系结构实验室</title>
    <link>http://localhost:1313/</link>
      <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <description>智能计算机体系结构实验室</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh-Hans</language><copyright>© 2024 智能计算机体系结构实验室 · 上海交通大学</copyright><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/logo.png</url>
      <title>智能计算机体系结构实验室</title>
      <link>http://localhost:1313/</link>
    </image>
    
    <item>
      <title>GIST: Improving Parameter Efficient Fine Tuning via Knowledge Interaction</title>
      <link>http://localhost:1313/publication/ruan2024gist/</link>
      <pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/ruan2024gist/</guid>
      <description></description>
    </item>
    
    <item>
      <title>From Raw Video to Pedagogical Insights: A Unified Framework for Student Behavior Analysis</title>
      <link>http://localhost:1313/publication/yu2024raw/</link>
      <pubDate>Wed, 07 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/yu2024raw/</guid>
      <description></description>
    </item>
    
    <item>
      <title>LAMM: Label Alignment for Multi-Modal Prompt Learning</title>
      <link>http://localhost:1313/publication/gao2024lamm/</link>
      <pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/gao2024lamm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Toward an end-to-end implicit addressee modeling for dialogue disentanglement</title>
      <link>http://localhost:1313/publication/gao2024mta/</link>
      <pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/gao2024mta/</guid>
      <description></description>
    </item>
    
    <item>
      <title>面向公安AI智能接警大模型自动问答系统</title>
      <link>http://localhost:1313/project/dialogue/</link>
      <pubDate>Tue, 23 Apr 2024 11:00:00 +0800</pubDate>
      <guid>http://localhost:1313/project/dialogue/</guid>
      <description></description>
    </item>
    
    <item>
      <title>iDAT: inverse Distillation Adapter-Tuning</title>
      <link>http://localhost:1313/publication/ruan2024idat/</link>
      <pubDate>Wed, 03 Apr 2024 14:00:05 +0800</pubDate>
      <guid>http://localhost:1313/publication/ruan2024idat/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Toward an end-to-end implicit addressee modeling for dialogue disentanglement</title>
      <link>http://localhost:1313/publication/li2024clapp/</link>
      <pubDate>Mon, 01 Apr 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/li2024clapp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Editing outdoor scenes with a large annotated synthetic dataset</title>
      <link>http://localhost:1313/publication/xie2024mta/</link>
      <pubDate>Sat, 02 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/xie2024mta/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning to Floorplan like Human Experts via Reinforcement Learning</title>
      <link>http://localhost:1313/publication/yan2024date/</link>
      <pubDate>Thu, 15 Feb 2024 14:00:05 +0800</pubDate>
      <guid>http://localhost:1313/publication/yan2024date/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Deep multimodal representation learning for generalizable person re-identification</title>
      <link>http://localhost:1313/publication/xiang-2024-deep/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/xiang-2024-deep/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Rethinking person re-identification via semantic-based pretraining</title>
      <link>http://localhost:1313/publication/xiang-2024-rethink/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/xiang-2024-rethink/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ege-unet: an efficient group enhanced unet for skin lesion segmentation</title>
      <link>http://localhost:1313/publication/ruan2023egeunet/</link>
      <pubDate>Wed, 05 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/ruan2023egeunet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>LiveChat: A Large-Scale Personalized Dialogue Dataset Automatically Constructed from Live Streaming</title>
      <link>http://localhost:1313/publication/gao2023livechat/</link>
      <pubDate>Mon, 05 Jun 2023 14:00:05 +0800</pubDate>
      <guid>http://localhost:1313/publication/gao2023livechat/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DynaSlim: Dynamic Slimming for Vision Transformers</title>
      <link>http://localhost:1313/publication/shi2023dynaslim/</link>
      <pubDate>Sun, 05 Mar 2023 14:00:05 +0800</pubDate>
      <guid>http://localhost:1313/publication/shi2023dynaslim/</guid>
      <description></description>
    </item>
    
    <item>
      <title>基于人工智能的floorplan自动生成与量化评价算法</title>
      <link>http://localhost:1313/project/floorpan/</link>
      <pubDate>Tue, 21 Feb 2023 11:00:00 +0800</pubDate>
      <guid>http://localhost:1313/project/floorpan/</guid>
      <description></description>
    </item>
    
    <item>
      <title>AV-TAD: Audio-Visual Temporal Action Detection with Transformer</title>
      <link>http://localhost:1313/publication/li2023avtad/</link>
      <pubDate>Wed, 15 Feb 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/li2023avtad/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CC-PoseNet: Towards human pose estimation in crowded classrooms</title>
      <link>http://localhost:1313/publication/yu2023ccposenet/</link>
      <pubDate>Wed, 15 Feb 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/yu2023ccposenet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MALUNet: A Multi-Attention and Light-weight UNet for Skin Lesion Segmentation</title>
      <link>http://localhost:1313/publication/ruan2022malunet/</link>
      <pubDate>Thu, 20 Oct 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/ruan2022malunet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Spatial Attention Guided Local Facial Attribute Editing</title>
      <link>http://localhost:1313/publication/xie2022spatial/</link>
      <pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/xie2022spatial/</guid>
      <description></description>
    </item>
    
    <item>
      <title>2022春 实验室任务规划</title>
      <link>http://localhost:1313/post/22-02-14-semester-task/</link>
      <pubDate>Mon, 14 Feb 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/22-02-14-semester-task/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;本科生课程《人工智能硬件综合实践课程》&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;本科生毕业设计&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;本科生PRP项目&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>2022年上半年论文列表</title>
      <link>http://localhost:1313/post/22-02-01-confence-list/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/22-02-01-confence-list/</guid>
      <description>&lt;p&gt;列表待更新&amp;hellip;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GOS: A Large-Scale Annotated Outdoor Scene Synthetic Dataset</title>
      <link>http://localhost:1313/publication/xie2022gos/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/xie2022gos/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SynPose: A Large-scale and Densely Annotated Synthetic Dataset for Human Pose Estimation in Classroom</title>
      <link>http://localhost:1313/publication/yu2022synthetic/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/yu2022synthetic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>祝贺实验室两篇论文被ICASSP 2022接收</title>
      <link>http://localhost:1313/post/22-01-22-paper-accepted/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/22-01-22-paper-accepted/</guid>
      <description>&lt;p&gt;祝贺&lt;/p&gt;
&lt;p&gt;谢铭烨同学的论文&amp;quot;GOS: A Large-Scale Annotated Outdoor Scene Synthetic Dataset&amp;quot; 和&lt;/p&gt;
&lt;p&gt;于泽芳同学的论文&amp;quot;SynPose: A Large-Scale and Densely Annotated Synthtic Dataset for Human Pose Estimation in Classroom&amp;quot;&lt;/p&gt;
&lt;p&gt;被ICASSP 2022所接收！&lt;/p&gt;
&lt;p&gt;ICASSP会议属于CCF B类会议。本次会议将于2022年5月在新加坡以混合模式召开。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>面向水声目标识别的深度学习网络快速在线学习方法</title>
      <link>http://localhost:1313/project/water/</link>
      <pubDate>Fri, 21 Jan 2022 11:00:00 +0800</pubDate>
      <guid>http://localhost:1313/project/water/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DFFCN: Dual Flow Fusion Convolutional Network for Micro Expression Recognition</title>
      <link>http://localhost:1313/publication/chen2021dffcn/</link>
      <pubDate>Sun, 05 Dec 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/chen2021dffcn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dynamic Channel Pruning for Real-Time Object Detection Networks</title>
      <link>http://localhost:1313/publication/jin2021dynamic/</link>
      <pubDate>Thu, 02 Dec 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/jin2021dynamic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Improving Abstractive Dialogue Summarization with Hierarchical Pretraining and Topic Segment</title>
      <link>http://localhost:1313/publication/qi2021improving/</link>
      <pubDate>Tue, 30 Nov 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/qi2021improving/</guid>
      <description></description>
    </item>
    
    <item>
      <title>2021年下半年论文列表</title>
      <link>http://localhost:1313/post/21-07-01-confence-list/</link>
      <pubDate>Thu, 24 Jun 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/21-07-01-confence-list/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;AAAI: AAAI Conference on Artificial Intelligence&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;CCF-A&lt;/li&gt;
&lt;li&gt;Deadline: 2021-08-30&lt;/li&gt;
&lt;li&gt;Topic: Artificial Intelligence, Machine Learning, Applications&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&#34;https://www.aaai.org/Conferences/AAAI-22/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.aaai.org/Conferences/AAAI-22/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ICLR: International Conference on Learning Representations&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Deadline: 2021-10-06&lt;/li&gt;
&lt;li&gt;Topic: Artificial Intelligence, Representation Learning&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&#34;https://iclr.cc/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://iclr.cc/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ICASSP: IEEE International Conference on Acoustics, Speech, and Signal Processing&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;CCF-B&lt;/li&gt;
&lt;li&gt;Deadline: 2021-10-01&lt;/li&gt;
&lt;li&gt;Topic: Deep Learning, Machine Learning for Signal Processing&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&#34;https://2022.ieeeicassp.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://2022.ieeeicassp.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ECAI: European Conference on Artificial Intelligence&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;CCF-B&lt;/li&gt;
&lt;li&gt;Deadline: 2021-11 (TBD)&lt;/li&gt;
&lt;li&gt;Topic: Artificial Intelligence, Machine Learning&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CVPR: IEEE Conference on Computer Vision and Pattern Recognition&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;CCF-A&lt;/li&gt;
&lt;li&gt;Deadline: 2021-11 (TBD)&lt;/li&gt;
&lt;li&gt;Topic: Deep Learning and Computer Vision&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ICME: IEEE International Conference on Multimedia and Expo&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;CCF-B&lt;/li&gt;
&lt;li&gt;Deadline: 2021-12 (TBD)&lt;/li&gt;
&lt;li&gt;Topic: Deep Learning and Multimedia&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>大学生课堂参与度的人工智能实时智慧评价关键技术研究</title>
      <link>http://localhost:1313/project/education/</link>
      <pubDate>Mon, 21 Jun 2021 11:00:00 +0800</pubDate>
      <guid>http://localhost:1313/project/education/</guid>
      <description>&lt;h3 id=&#34;背景介绍&#34;&gt;背景介绍&lt;/h3&gt;
&lt;p&gt;我国教育部于 2004 年启动“高等学校教学质量与教学改革工程”，在 2007年全面实施该工程，并启动了人才培养数据库及预测机制研究项目。十九大也进一步提出要实现高等教育内涵式发展，提升教育质量成为高等教育内涵式发展的第一要务。本项目从教育评价经典理论出发，探究了机器视觉和自然语言处理等领域最新人工智能技术在大学课堂学生参与行为的表征建模和分析报告生成等关键任务中的应用范式。&lt;/p&gt;
&lt;h3 id=&#34;应用场景和方案&#34;&gt;应用场景和方案&lt;/h3&gt;
&lt;p&gt;项目以上海交通大学课堂真实视频为参考，构建了教室场景密集坐姿人群合成数据集 SynPose 和典型课堂参与行为关节点时序数据集，在此基础上设计了密集遮挡人群姿态估计模型 CC-PoseNet 和多模态时序动作检测模型 AV-TAD，进而提出了从原始课堂视频到教育学视角学生行为分析与反馈报告生成的端到端智能化系统，开创性地利用 GPT4 等大语言模型弥合了教育理论与视觉表征之间的认知层次差异，为教育学视角下的课堂行为自动化观察、 分析与评价反馈生成提供了一种高效可行的智能化实施方案。&lt;/p&gt;
&lt;h3 id=&#34;已有成果&#34;&gt;已有成果&lt;/h3&gt;
&lt;p&gt;项目执行期间共计发表/录用多篇CCF推荐会议/期刊论文和高水平教育类论文，其中主线任务所形成的结论性成果“端到端课堂行为分析框架”被EAAI2024接收，阶段性成果教室场景姿态估计数据集 SynPose、遮挡人群姿态估计模型 CC-PoseNet、“视频-音频”动作检测模型 AV-TAD发表于ICASSP2022/2023，辅助任务中多轮对话摘要模型EHMNet和多模态提示学习标签对齐LAMM分别发表/录用于EMNLP2022和AAAI2024。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>深度学习压缩剪枝算法研究与应用</title>
      <link>http://localhost:1313/project/compress/</link>
      <pubDate>Mon, 21 Jun 2021 11:00:00 +0800</pubDate>
      <guid>http://localhost:1313/project/compress/</guid>
      <description>&lt;h3 id=&#34;背景介绍&#34;&gt;背景介绍&lt;/h3&gt;
&lt;p&gt;尽管深度学习算法模型性能强大，然而由于其参数量多、运行所需要的算力极其庞大，使得深度学习网络难以在存储资源或计算资源受限的平台上部署运行，只能部署在GPU等硬件设备上进行加速计算。这样的特点大大限制了其应用场景，要求我们对深度学习网络模型进行优化和压缩，减少其对资源的需求，以便灵活部署到低资源的硬件平台中。&lt;/p&gt;
&lt;h3 id=&#34;应用场景&#34;&gt;应用场景&lt;/h3&gt;
&lt;p&gt;模型压缩应用于算力有限的边缘设备，比如车载平台，无人机等。在不影响准确性的前提下，制作能在边缘设备约束下运行的更小的模型具有广泛的应用价值。&lt;/p&gt;
&lt;h3 id=&#34;已有成果&#34;&gt;已有成果&lt;/h3&gt;
&lt;p&gt;设计了一种动态稀疏方法，该方案一方面加深对于模型冗余参数的挖掘力度，另一方面细粒度平衡稀疏训练和精度训练的制约关系。实现了更高剪枝率下的精度保持。&lt;/p&gt;


















&lt;figure id=&#34;figure-不同压缩方式对比图&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./structure.png&#34; data-caption=&#34;不同压缩方式对比图&#34;&gt;


  &lt;img src=&#34;./structure.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    不同压缩方式对比图
  &lt;/figcaption&gt;


&lt;/figure&gt;

</description>
    </item>
    
    <item>
      <title>基于GAN的图片属性编辑</title>
      <link>http://localhost:1313/project/gan-editing/</link>
      <pubDate>Mon, 21 Jun 2021 10:35:00 +0800</pubDate>
      <guid>http://localhost:1313/project/gan-editing/</guid>
      <description>&lt;h3 id=&#34;背景介绍&#34;&gt;背景介绍&lt;/h3&gt;
&lt;p&gt;生成对抗网络（Generative Adversarial Networks， GAN）由两个基础神经网络即生成器（Generator）和判别器（Discriminator）所组成，其中一个用于生成内容，另一个则用于判别生成的内容。GAN能够学习数据集内的特征，进而生成逼近真实数据的高质量的图片。&lt;/p&gt;
&lt;p&gt;GAN在图像合成领域的应用已经十分广泛。近期的一些研究表明，在学习合成图像时，GAN 会自发地在隐空间（latent space）中表示出多种可解释属性，如用于人脸合成的性别特征、用于场景合成的光照条件。通过正确识别这些语义，我们可以将 GAN 学习到的知识重新利用，合理地控制图像生成过程，从而实现图像编辑功能的更广泛应用，如人脸操纵和场景编辑。&lt;/p&gt;
&lt;p&gt;解释 GAN 潜在空间的关键点在于找到与人类可理解属性相对应的子空间。通过这种方法，将潜码（latent code）向特定子空间的方向移动，即可对应地改变合成图像的语义。&lt;/p&gt;
&lt;h3 id=&#34;应用场景&#34;&gt;应用场景&lt;/h3&gt;
&lt;p&gt;人脸图像内含有很多的语义属性，例如表情、头发颜色、年龄等，利用GAN可以实现图像的属性编辑，比如改变表情、改变头发颜色。人脸属性编辑可应用在娱乐场景中，比如短视频中的特效，可实现年龄转换、表情变换等功能，也可用于辅助诸如人脸识别，表情识别等其他任务。&lt;/p&gt;
&lt;h3 id=&#34;已有成果&#34;&gt;已有成果&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;设计了一个针对人脸表情编辑的框架，该方案使得编辑后生成的图片质量更高、更真实。


















&lt;figure id=&#34;figure-人脸表情编辑效果&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./face.png&#34; data-caption=&#34;人脸表情编辑效果&#34;&gt;


  &lt;img src=&#34;./face.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    人脸表情编辑效果
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;利用GTA V自动构建了带标注的室外场景数据集。


















&lt;figure id=&#34;figure-gta-v室外场景数据集&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./gos.png&#34; data-caption=&#34;GTA V室外场景数据集&#34;&gt;


  &lt;img src=&#34;./gos.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    GTA V室外场景数据集
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>行人重识别</title>
      <link>http://localhost:1313/project/reid/</link>
      <pubDate>Mon, 21 Jun 2021 10:30:00 +0800</pubDate>
      <guid>http://localhost:1313/project/reid/</guid>
      <description>&lt;h3 id=&#34;背景介绍&#34;&gt;背景介绍&lt;/h3&gt;
&lt;p&gt;行人重识别（Person re-identification, Re-ID)，也称为行人再识别或跨镜追踪；主要实现从一个摄像头捕获的目标行人，到其他不同摄像头检索是否存在相同行人，即进行跨摄像头检索。&lt;/p&gt;
&lt;h3 id=&#34;应用场景&#34;&gt;应用场景&lt;/h3&gt;
&lt;p&gt;行人重识别技术可以弥补目前固定摄像头的视觉局限, 并可与行人检测、行人跟踪技术相结合, 应用于视频监控、智能安防等领域。&lt;/p&gt;
&lt;h3 id=&#34;已有成果&#34;&gt;已有成果&lt;/h3&gt;
&lt;p&gt;行人重识别领域由于安全隐私、数据可获取性、标注难度等因素的限制，高质量大规模的真实标注数据依然非常稀缺。针对这类问题，我们针对具体任务场景，利用GTA-5游戏引擎自动构建了多属性有标注数据集。


















&lt;figure id=&#34;figure-来自标注数据集的行人样本&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./gpr.png&#34; data-caption=&#34;来自标注数据集的行人样本&#34;&gt;


  &lt;img src=&#34;./gpr.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    来自标注数据集的行人样本
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;已发表论文&#34;&gt;已发表论文&lt;/h3&gt;
&lt;p&gt;[1] Xiang S, Fu Y, You G, et al. Unsupervised domain adaptation through synthesis for person re-identification[C]//2020 IEEE International Conference on Multimedia and Expo (ICME). IEEE, 2020: 1-6. &lt;a href=&#34;../publication/xiang-2020-unsupervised/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] Xiang S, Fu Y, You G, et al. Taking A Closer Look at Synthesis: Fine-Grained Attribute Analysis for Person Re-Identification[C]//ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2021: 3765-3769. &lt;a href=&#34;../publication/xiang-2021-taking/&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Attention Based Facial Expression Manipulation</title>
      <link>http://localhost:1313/publication/wang2021attention/</link>
      <pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/wang2021attention/</guid>
      <description></description>
    </item>
    
    <item>
      <title>招收2022级硕士研究生</title>
      <link>http://localhost:1313/post/21-06-21-recruit/</link>
      <pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/21-06-21-recruit/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/9EzRluUhheKG1JvmhEBZ4A&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;上海交通大学微纳电子学系2022级 直硕/直博 研究生优才夏令营通知&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;报名时间：即日起至2021年6月28日&lt;/p&gt;
&lt;p&gt;欢迎广大学子报考iCAT实验室！&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>iCAT主页启动</title>
      <link>http://localhost:1313/post/21-03-18-homepage-start/</link>
      <pubDate>Thu, 18 Mar 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/21-03-18-homepage-start/</guid>
      <description>&lt;p&gt;庆祝iCAT主页重新启动！
请实验室各位成员及时补充个人相关信息！&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>博士组会汇报</title>
      <link>http://localhost:1313/event/21-03-09-phd-pre/</link>
      <pubDate>Tue, 09 Mar 2021 13:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/21-03-09-phd-pre/</guid>
      <description>&lt;p&gt;生成器：利用随机采样的隐空间编码生成真实度极高的合成图片，例如StyleGAN等&lt;/p&gt;
&lt;p&gt;编码器：将真实图片转换为隐空间编码，以便于后续的编辑和生成&lt;/p&gt;
&lt;p&gt;预测器：判断生成图片的语义信息，例如人物的性别、是否微笑等&lt;/p&gt;
&lt;p&gt;属性编辑：对隐空间编码进行特定向量方向的操控，以达到对图片属性编辑的目的&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2021年上半年论文列表</title>
      <link>http://localhost:1313/post/21-03-01-confence-list/</link>
      <pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/21-03-01-confence-list/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;International Conference on Multimodla Interaction (ICMI)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;May 2021&lt;/li&gt;
&lt;li&gt;CCF-C&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;International Conference on Neural Information Processing (ICONIP)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;June 2021&lt;/li&gt;
&lt;li&gt;CCF-C&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;International Conference on Tools with Artifical Intelligence (ICTAI)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;July 2021&lt;/li&gt;
&lt;li&gt;CCF-C&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>祝贺向孙程同学的论文被ICASSP&#39;21录用</title>
      <link>http://localhost:1313/post/20-12-02-paper-accepted/</link>
      <pubDate>Thu, 28 Jan 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/20-12-02-paper-accepted/</guid>
      <description>&lt;p&gt;祝贺向孙程同学的论文&amp;quot;Taking a Closer Look at Synthesis: Fine-grained Attribute Analysis for Person Re-Identification&amp;quot;被ICASSP&#39;21所录用！&lt;/p&gt;
&lt;p&gt;该会议属于CCF B类会议。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Taking A Closer Look at Synthesis: Fine-Grained Attribute Analysis for Person Re-Identification</title>
      <link>http://localhost:1313/publication/xiang-2021-taking/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/xiang-2021-taking/</guid>
      <description></description>
    </item>
    
    <item>
      <title>实验室服务器使用说明</title>
      <link>http://localhost:1313/post/21-01-01-server-usage/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/21-01-01-server-usage/</guid>
      <description>&lt;p&gt;使用服务器时请自觉遵守使用说明！&lt;/p&gt;
&lt;h3 id=&#34;服务器种类&#34;&gt;服务器种类&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;.158：Nvidia Tesla P100 SXM2 （四核，16GB）&lt;/li&gt;
&lt;li&gt;.249：Nvidia RTX 3090*4 （单核，24GB）&lt;/li&gt;
&lt;li&gt;本地：Nvidia RTX 1080 Ti （单核，11GB）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;载入服务器模块&#34;&gt;载入服务器模块&lt;/h3&gt;
&lt;p&gt;每次登入服务器时均需要加载&lt;/p&gt;
&lt;h4 id=&#34;显示当前可用的软件清单&#34;&gt;显示当前可用的软件清单&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;module av&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;加载常用模块&#34;&gt;加载常用模块&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;module load anaconda3/2019.10 #亦可在自己路径下独立安装anaconda
module load cuda/11.1
module load cudnn/8.0.5
module load gcc/7.3.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;conda简要使用说明&#34;&gt;conda简要使用说明&lt;/h3&gt;
&lt;h4 id=&#34;初始化conda-shell&#34;&gt;初始化conda shell&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;conda init bash&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;创建虚拟环境以testenv举例&#34;&gt;创建虚拟环境（以testenv举例）&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;conda create -n testenv&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;激活虚拟环境&#34;&gt;激活虚拟环境&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;conda activate testenv&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;安装软件包&#34;&gt;安装软件包&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;conda install numpy&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;conda install pytorch=0.4.0 # 指定具体版本&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;退出当前的虚拟环境&#34;&gt;退出当前的虚拟环境&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;conda deactivate&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;查看所有的虚拟环境&#34;&gt;查看所有的虚拟环境&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;conda env list&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;查看当前虚拟环境安装包&#34;&gt;查看当前虚拟环境安装包&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;conda list&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;删除虚拟环境及其下面的所有包&#34;&gt;删除虚拟环境及其下面的所有包&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;conda remove -n testenv —-all&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;其他说明&#34;&gt;其他说明&lt;/h3&gt;
&lt;h4 id=&#34;软件最低版本需求&#34;&gt;软件最低版本需求&lt;/h4&gt;
&lt;p&gt;在3090上低于该版本将无法正常运行需要GPU的程序&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;PyTorch&amp;gt;=1.7.0
Tensorflow&amp;gt;=2.4.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;服务器资源的分配&#34;&gt;服务器资源的分配&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;使用&lt;code&gt;nvidia-smi&lt;/code&gt;或者&lt;code&gt;gpustat&lt;/code&gt;(需使用pip或conda安装)查看当前服务器GPU使用状态&lt;/li&gt;
&lt;li&gt;多数程序运行时会默认占用所有可用的GPU，需要长时间使用GPU时，在运行指令前添加&lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt;指定具体运行的GPU，例如&lt;code&gt;CUDA_VISIBLE_DEVICES=0 python main.py&lt;/code&gt;即指定在0号GPU上运行程序&lt;/li&gt;
&lt;li&gt;在服务器资源紧张时，将会根据任务优先级对资源进行协调（例如近期需要投会议或期刊的同学可以优先使用）&lt;/li&gt;
&lt;li&gt;请注意自己home路径下的硬盘占用情况，定期清理临时文件&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Attribute analysis with synthetic dataset for person re-identification</title>
      <link>http://localhost:1313/publication/xiang-2020-attribute/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/xiang-2020-attribute/</guid>
      <description></description>
    </item>
    
    <item>
      <title>基于Intel FPGA技术的合作项目开发</title>
      <link>http://localhost:1313/project/intel/</link>
      <pubDate>Mon, 21 Jan 2019 11:00:00 +0800</pubDate>
      <guid>http://localhost:1313/project/intel/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Deep unsupervised progressive learning for distant domain adaptation</title>
      <link>http://localhost:1313/publication/xiang-2019-deep/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/xiang-2019-deep/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:1313/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/admin/config.yml</guid>
      <description></description>
    </item>
    
    <item>
      <title>关于我们</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description></description>
    </item>
    
    <item>
      <title>实验室项目</title>
      <link>http://localhost:1313/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/</guid>
      <description></description>
    </item>
    
    <item>
      <title>团队成员</title>
      <link>http://localhost:1313/people/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/people/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
